---
description: Complete project planning workflow from PRD creation to task execution with POC-first development methodology
globs: tasks/**/*.md, tasks/**/*.mdc,*.mdc
alwaysApply: false
---

# Complete Project Planning Workflow

This rule provides the comprehensive workflow for planning and executing projects using POC-first development methodology.

## üéØ **Overview: The Three-Phase Journey**

```
üìã Planning ‚Üí üöÄ POC ‚Üí üé® Demo ‚Üí üè≠ Production
   (Hours)    (Hours)   (1-2 Days)  (Ongoing)
```

**Core Philosophy**: Get something visual and interactive ASAP, then progressively enhance.

## üìã **Phase 0: Project Planning**

Do not skip steps. Require explicit user confirmation (reply "Go") before proceeding to the next step.

#### Attachment/Trigger Summary
- Auto-attach when editing or referencing files under `tasks/**` (PRDs and task lists).
- Manually mention `@project-planning` to force-include during planning conversations.
- Works in conjunction with `@process-task-list`, `@memory`, and `@mcp-browser-testing`.

### Step 1: Create PRD (Product Requirements Document)
**CRITICAL**: When user references project planning:
1. **NEVER write a PRD immediately** - start with clarifying questions
2. **Sequential questioning** - ask one question, wait for answer
3. **Multiple-choice questions** - present options a,b,c,d... or "choose for me". If you choose for the user, state your selection and a brief rationale; the user can accept or change it.
4. **Max 10 questions** for MVP scope, after 10 questions, ask the user if he wants to continue with the next 10 questions or let AI answer for him.
5. **Save as** `tasks/prd-[feature-name].md`

**Outputs**
- File created: `tasks/prd-[feature-name].md`
- State checkpoint: Pause and wait for "Go" before proceeding to Step 2.

#### Enforcement and Auto-Actions
- Auto-create `tasks/prd-[feature-name].md` immediately after completing discovery + tech questions (or when the user says "choose for me").
- Before asking to proceed to Step 2, verify the file exists; if missing, create it and announce the path.
- Do not proceed to Step 2 unless the file exists. If file write fails, stop and ask for an alternative path or permission to create the `tasks/` directory.

**Example Questions Flow**:
```
Q1: What problem are we solving?
Q2: Who is the primary user?
Q3: What's the core user flow?
Q4: What defines success?
...
Q20: Any technical constraints?
```

#### Technology Stack Discovery Questions (sequential, multiple-choice)
Ask one at a time. After 10, ask to continue or choose defaults. If unsure, the user can reply "choose for me" to use recommended defaults.

```
TS1: Frontend framework?
  a) React  b) Vue  c) Svelte  d) None/Vanilla  e) Other  f) Choose for me

TS2: Language and typing?
  a) TypeScript  b) JavaScript (ES2022+)  c) Both (gradual TS)  d) Other  e) Choose for me

TS3: Rendering/application style?
  a) Next.js (SSR/SSG)  b) SPA (Vite)  c) Static site  d) Other  e) Choose for me

TS4: State and data fetching?
  a) React Query/SWR  b) Redux Toolkit  c) Zustand/Context  d) None (local state)  e) Other  f) Choose for me

TS5: Styling/UI?
  a) Tailwind CSS  b) CSS-in-JS (Styled/Emotion)  c) Component lib (MUI/Chakra/Ant)  d) CSS/Sass  e) Other  f) Choose for me

TS6: Backend/runtime?
  a) Node.js + Express/Fastify/Nest  b) Python + Flask/FastAPI/Django  c) No backend (static/API-as-a-service)  d) Other  e) Choose for me

TS7: API protocol?
  a) REST  b) GraphQL  c) tRPC  d) gRPC  e) Other  f) Choose for me

TS8: Database/storage?
  a) Postgres  b) MySQL  c) MongoDB  d) Serverless (Dynamo/Firestore/KV/Blob)  e) Other  f) Choose for me

TS9: Cloud/deploy target?
  a) Vercel/Netlify  b) AWS  c) GCP  d) Azure  e) On‚Äëprem  f) Other  g) Choose for me

TS10: Testing focus?
  a) Unit (Vitest/Jest)  b) E2E (Playwright/Cypress)  c) API (Supertest)  d) Accessibility (axe/playwright-a11y)  e) All of the above  f) Choose for me
```

Pause/Confirm
- Ask: "Proceed to Step 2: Generate Task List? Reply 'Go' to continue or 'Adjust PRD' to iterate."

### Step 2: Generate Task List

Make `1.0 Project setup` the first parent task. Keep PRD content separate in Step 1.

1.0 Project setup ‚Äî scope (no duplication):
- Repo and tooling bootstrap (package manager init, linting/formatting, `.gitignore`).
- Import and tailor curated rules per Step 3 (do not restate details here).
- Baseline README and scripts; use commands listed under "Development Commands".
- Create minimal directory scaffolding per "File Structure" in Phase 1.
- Set up VS Code configuration:
  - Create `.vscode` directory with:
    - `launch.json` for debugging configurations (Next.js, tests, etc.)
    - `tasks.json` for common development tasks (build, test, lint)
- Ensure `tasks/prd-[feature-name].md` and `tasks/tasks-[feature-name].md` exist with scaffolds.
- Optional: CI skeleton and deployment preview links (reference your team standards).

**Process**:
1. Generate 5-10 **parent tasks** covering full implementation (starting with `1.0 Project setup`)
2. **PAUSE** and wait for "Go" confirmation
3. Break into **sub-tasks** (‚â§1-2 hours each)
4. Save as `tasks/tasks-[feature-name].md`

**Outputs**
- File created: `tasks/tasks-[feature-name].md`
- State checkpoint: Pause and wait for "Go" before proceeding to Step 3.

#### Enforcement and Auto-Actions
- Immediately write the parent tasks to `tasks/tasks-[feature-name].md` once generated.
- Include a "Subtasks" scaffold section under each parent (placeholder) to ensure structure exists.
- Upon user reply "Go" (breakdown), auto-write 1‚Äì2 hour subtasks beneath each parent in the same file without additional prompts.
- Do not proceed to Step 3 until the tasks file exists and contains at least one subtask under `1.0`.
- If the file or sections are missing, self-heal by creating/updating the file and report what was added.

**Task Structure**:
```markdown
- [ ] 1.0 Project setup
  - [ ] 1.1 Repo/tooling initialized (pnpm, linting, formatting)
  - [ ] 1.2 Curated rules imported and tailored in `.cursor/rules`
  - [ ] 1.3 VS Code configuration added (.vscode/launch.json, tasks.json)
  - [ ] 1.4 PRD and tasks scaffolds verified under `tasks/`
- [ ] 2.0 Core Functionality (POC Phase)
  - [ ] 2.1 Basic HTML structure
  - [ ] 2.2 Core interaction working
  - [ ] 2.3 Visual feedback
- [ ] 3.0 Enhanced Demo (Demo Phase)
  - [ ] 3.1 Realistic sample data
  - [ ] 3.2 Smooth animations
- [ ] 4.0 Production Ready (Production Phase)
  - [ ] 4.1 Error handling
  - [ ] 4.2 Performance optimization
```

Pause/Confirm
- Ask: "Proceed to Step 3: Import and tailor rules? Reply 'Go' to continue or 'Revise tasks' to iterate."

### Step 3: Import and tailor rules from `@rules-directory/`
After the tech stack is chosen, import relevant curated rules from `@rules-directory/`, copy them into `.cursor/rules/`, and edit to fit the project.

1. Locate relevant rules
   - Examples: `react.mdc`, `typescript.mdc`, `tailwind.mdc`, `python.mdc`, `rust.mdc`.
2. Copy into project rules
   - Place in `.cursor/rules/` at the project root or use nested rules in subprojects (see below).
3. Edit MDC header (Rule anatomy)
   - `description`: Clear, concise purpose for when to apply this rule.
   - `globs`: Scope to file patterns that should auto-attach (e.g., `["web/**/*.tsx", "*.tsx"]`).
   - `alwaysApply`: `true` only for essentials; otherwise `false` and rely on globs or manual attach.
4. Choose rule type (per Cursor docs)
   - Always: Always included in context.
   - Auto Attached: Included when files matching `globs` are referenced.
   - Agent Requested: Available; AI decides whether to include (must have `description`).
   - Manual: Only included when explicitly mentioned via `@ruleName`.
5. Keep rules focused
   - Keep under 500 lines; split into multiple composable rules if needed. Provide concrete examples and referenced files.

**Outputs**
- Curated rules copied into `.cursor/rules/` and tailored with accurate `description`, `globs`, and `alwaysApply`.
- State checkpoint: Pause and wait for "Go" before starting Phase 1 (POC Development).

#### Enforcement and Auto-Actions
- Auto-locate relevant rules in `rules-directory/` and copy into `.cursor/rules/` with tailored headers for this project.
- Refuse to begin Phase 1 unless at least React, TypeScript, Tailwind, and testing rules are present and scoped via `globs`.
- For multi-package repos, also place nested rules under affected subfolders (e.g., `frontend/.cursor/rules/`).

Nested rules (auto attach by directory)
Organize rules by placing `.cursor/rules` in relevant folders. Rules inside these folders auto-attach when files in that directory are referenced.

```
project/
  .cursor/rules/                 # Project-wide rules
  frontend/
    .cursor/rules/               # Frontend-specific rules (e.g., React, Tailwind)
  backend/
    .cursor/rules/               # Backend-specific rules (e.g., Node, Python)
```

Example: Tailoring a copied rule

```md
---
description: React component standards for web frontend
globs: ["web/**/*.tsx", "*.tsx"]
alwaysApply: false
---

- Use functional components and hooks.
- Co-locate tests: `Component.tsx` with `Component.test.tsx`.
- Prefer Tailwind for styling; avoid inline styles.
- Export prop types; keep components pure and presentational where possible.
```

Why
- Ensures rules are actionable, scoped, and automatically applied where relevant.
- Aligns with Cursor best practices for rule anatomy, nested rules, and reusability.

Pause/Confirm
- Ask: "Proceed to Phase 1 (POC Development)? Reply 'Go' to start or 'Adjust rules' to refine."

### Pre‚ÄëFlight Checklist (must be true before Phase 1)
- [ ] `tasks/prd-[feature-name].md` exists and summarizes decisions
- [ ] `tasks/tasks-[feature-name].md` exists with parent tasks and subtasks
- [ ] `tasks/tasks-[feature-name].md` includes `1.0 Project setup` as the first parent
- [ ] `.cursor/rules/` contains tailored React, TypeScript, Tailwind, and testing rules

## üöÄ **Phase 1: POC Development**

Do not begin until Step 3 is confirmed with a "Go" reply.

### Technology Stack (from @memory.mdc)
**Default Stack**:
```bash
# Initialize with preferred stack
pnpm init
pnpm add next react react-dom tailwindcss recharts zod
pnpm add -D vitest playwright @vitest/ui msw @testing-library/dom
```

### POC Implementation Priorities
1. ‚úÖ **Visual First** - Something users can see immediately
2. ‚úÖ **Core Functionality** - Main user flow works
3. ‚úÖ **Hardcoded Data** - Skip API complexity
4. ‚ùå Skip error handling, edge cases, optimization

**File Structure**:
```
src/
‚îú‚îÄ‚îÄ poc/                    # Phase 1: Quick prototypes
‚îú‚îÄ‚îÄ demo/                   # Phase 2: Polished demos  
‚îú‚îÄ‚îÄ core/                   # Phase 3: Production code
‚îî‚îÄ‚îÄ tests/                  # Test files
```

### POC Success Criteria
- [ ] Users can see and interact with the core feature
- [ ] Main user flow works (even if basic)
- [ ] Visual feedback is present
- [ ] Demo is shareable via URL
- [ ] Completed within hours, not days

## üé® **Phase 2: Demo Enhancement**

Do not begin until Phase 1 success criteria are met and the user replies "Go".

### Demo Priorities
1. ‚úÖ **Realistic Data** - Sample data representing real use cases
2. ‚úÖ **Smooth Interactions** - Animations and transitions
3. ‚úÖ **Basic Error Handling** - Common failure cases
4. ‚úÖ **Cross-Device Testing** - Mobile and desktop
5. ‚úÖ **Visual Polish** - Improved design

### Demo Success Criteria
- [ ] Realistic data and interactions
- [ ] Smooth animations (targeting 60fps)
- [ ] Works on mobile and desktop
- [ ] Basic error states handled
- [ ] Visually polished
- [ ] Basic test coverage

## üè≠ **Phase 3: Production Ready**

Do not begin until Phase 2 success criteria are met and the user replies "Go".

### Production Priorities
1. ‚úÖ **Error Handling** - Comprehensive error handling and recovery
2. ‚úÖ **Performance** - 60fps animations, memory management
3. ‚úÖ **Accessibility** - WCAG compliance, keyboard navigation
4. ‚úÖ **Security** - Input validation, XSS prevention
5. ‚úÖ **Monitoring** - Analytics, error reporting
6. ‚úÖ **Testing** - Unit, integration, cross-browser tests

### Production Success Criteria
- [ ] 80% test coverage achieved
- [ ] Performance benchmarks met (60fps)
- [ ] Accessibility compliance (WCAG AA)
- [ ] Security validation passed
- [ ] Error rate <1%
- [ ] Production monitoring active

## üîÑ **Task Execution Protocol**

### During Development
1. **Pick next sub-task** from task list
2. **Implement** code, tests, docs for this sub-task only
3. **Validate locally** - run relevant tests
4. **Update task list** - mark `[x]` completed
5. **Collaboration Protocol**:
   - **Ask one question at a time** during reviews
   - **Wait for acknowledgement** before proceeding
   - **Pause for approval** when collaborating

### Git Workflow
```bash
# Create feature branch per parent task
git checkout -b feat/feature-name

# Commit with conventional commits + PRD references
git commit -m "feat: implement POC (FR-2)" \
           -m "- Adds basic functionality" \
           -m "Related to Task 1.0 in PRD"

# Rebase before PR (avoid merge commits)
git rebase main
```

## üõ†Ô∏è **Development Commands**

### Project Setup
```bash
# Initialize project structure
mkdir -p src/{poc,demo,core,components,utils} tests/{unit,integration,e2e} storybook/learned-memories

# Setup Storybook documentation mirroring
node scripts/sync-mdc-to-mdx.js .cursor/rules/learned-memories.mdc storybook/learned-memories

# Start development server
pnpm dev  # or python3 -m http.server 8080 for static demos
```

### Testing Commands
```bash
# Run tests (following @testing-patterns.mdc)
pnpm test                    # vitest
pnpm test:watch             # vitest --watch  
pnpm test:coverage          # vitest --coverage
pnpm test:performance       # vitest --testNamePattern='performance'
pnpm test:a11y              # vitest --testNamePattern='accessibility'
```

## üåç **Environment Management**

### Environment Configuration
```javascript
// config/environments.js
export const environments = {
  development: {
    apiEndpoint: 'http://localhost:3000/api',
    enableDebugLogs: true,
    mockData: true,
    performanceMonitoring: false
  },
  demo: {
    apiEndpoint: 'https://demo-api.example.com',
    enableDebugLogs: true,
    mockData: false,
    performanceMonitoring: true
  },
  production: {
    apiEndpoint: 'https://api.example.com',
    enableDebugLogs: false,
    mockData: false,
    performanceMonitoring: true
  }
};
```

## üß± **Infrastructure Preferences**

### POC/Demo (Default)
- Run the web app locally with pnpm (do not dockerize the main app).
  ```bash
  pnpm install
  pnpm dev
  ```
- Use Docker Compose only for infrastructure dependencies (e.g., database, Mailpit).
  ```bash
  docker compose up -d
  docker compose logs -f | cat
  docker compose down -v
  ```
- Suggested files at project root:
  - `docker-compose.yml` orchestrating infra services only (no `web` service)

Minimal compose example (adapt as needed):

```yaml
# docker-compose.yml
services:
  postgres:
    image: postgres:16-alpine
    environment:
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_DB=app
    ports:
      - "5432:5432"
    volumes:
      - db_data:/var/lib/postgresql/data
  mailpit:
    image: axllent/mailpit:latest
    ports:
      - "8026:8025"
      - "8025:8025"
volumes:
  db_data:
```

### Production (When graduating from Demo)
- Prefer managed cloud infrastructure. Typical paths:
  - Frontend: Vercel/Netlify (Next.js/SPA) or container on AWS/GCP/Azure
  - APIs/Workers: Containers on AWS ECS/EKS, GCP Cloud Run/GKE, or Azure
  - Data: Managed Postgres/MySQL/NoSQL; managed object/blob storage
- Establish CI/CD to build images, push to a registry, and deploy per environment.
- Harden with observability, security scanning, and secret management.

### Error Handling Standards
```javascript
// Good: Typed errors (never return null silently)
class ValidationError extends Error {
  constructor(message, field) {
    super(message);
    this.name = 'ValidationError';
    this.field = field;
  }
}

// Use Result type pattern with Zod schemas
function validateUser(data) {
  const result = UserSchema.safeParse(data);
  if (!result.success) {
    throw new ValidationError('Invalid user data', result.error);
  }
  return result.data;
}
```

## üéØ **Success Metrics**

### Development Velocity
- **POC**: Working demo within 4-8 hours
- **Demo**: Polished version within 1-2 days
- **Production**: Incremental enhancement over weeks

### Quality Metrics
- **Performance**: >55fps on mid-range devices
- **Accessibility**: WCAG AA compliance
- **Testing**: >80% code coverage
- **Error Rate**: <1% in production
- **User Engagement**: Measurable improvement over baseline

## üöÄ **Key Principles**

1. **Start Visual** - Always create something users can see first
2. **Iterate Rapidly** - POC ‚Üí Demo ‚Üí Production progression
3. **User Feedback Early** - Deploy demos immediately
4. **Progressive Enhancement** - Add complexity only when core works
5. **Production Last** - Don't over-engineer until concept is validated

**Remember**: *A working demo is worth a thousand specifications!*

## üìö **Quick Reference**

| Phase | Duration | Focus | Success Criteria |
|-------|----------|-------|------------------|
| **POC** | Hours | Visual + Core Function | Users can interact |
| **Demo** | 1-2 Days | Polish + Realistic Data | Cross-device works |
| **Production** | Ongoing | Robust + Scalable | Production ready |

## ü§ñ **Agent Self-Enhancement Protocol**

When starting a new project, the agent should:

1. **Analyze project requirements** from user input
2. **Automatically add relevant specialized rules**:
   - `@code-developer.mdc` for web applications
   - `@testing-patterns.mdc` for projects requiring testing
   - Domain-specific rules as needed (e.g., performance, realtime, data)
3. **Follow the complete workflow** from PRD ‚Üí POC ‚Üí Demo ‚Üí Production
4. **Update rules** based on project learnings and patterns
5. **Maintain rule quality** by consolidating and refining based on usage

**Next Steps**: Start with sequential questioning to create your PRD!

## üîó Related Rules

- `@process-task-list` ‚Äî execution protocol for task lists derived from the PRD
- `@memory` ‚Äî capture project decisions and preferences as they are learned
- `@mcp-browser-testing` ‚Äî manual E2E validation before advancing milestones